# In this exercise you will train a CNN on the FULL Cats-v-dogs dataset
# This will require you doing a lot of data preprocessing because
# the dataset isn't split into training and validation for you
# This code block has all the required inputs
import os
import zipfile
import random
import tensorflow as tf
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from shutil import copyfile
In [4]:
# This code block downloads the full Cats-v-Dogs dataset and stores it as 
# cats-and-dogs.zip. It then unzips it to /tmp
# which will create a tmp/PetImages directory containing subdirectories
# called 'Cat' and 'Dog' (that's how the original researchers structured it)
# If the URL doesn't work, 
# .   visit https://www.microsoft.com/en-us/download/confirmation.aspx?id=54765
# And right click on the 'Download Manually' link to get a new URL

!wget --no-check-certificate \
    "https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip" \
    -O "/tmp/cats-and-dogs.zip"

local_zip = '/tmp/cats-and-dogs.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp')
zip_ref.close()
--2019-04-29 12:45:42--  https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip
Resolving download.microsoft.com (download.microsoft.com)... 184.26.100.152, 2600:1408:8400:3a9::e59, 2600:1408:8400:385::e59
Connecting to download.microsoft.com (download.microsoft.com)|184.26.100.152|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 824894548 (787M) [application/octet-stream]
Saving to: ‘/tmp/cats-and-dogs.zip’

/tmp/cats-and-dogs. 100%[===================>] 786.68M  6.08MB/s    in 2m 11s  

2019-04-29 12:47:54 (5.99 MB/s) - ‘/tmp/cats-and-dogs.zip’ saved [824894548/824894548]

In [5]:
print(len(os.listdir('/tmp/PetImages/Cat/')))
print(len(os.listdir('/tmp/PetImages/Dog/')))

# Expected Output:
# 12501
# 12501
12501
12501
In [0]:
import shutil
try:
    shutil.rmtree("/tmp/cats-v-dogs")
except:
    pass
In [0]:
# Use os.mkdir to create your directories
# You will need a directory for cats-v-dogs, and subdirectories for training
# and testing. These in turn will need subdirectories for 'cats' and 'dogs'
try:
    #If you made any mistake creating directories, uncomment the following line which will delete cats-v-dogs

#shutil.rmtree("/tmp/cats-v-dogs")
    os.mkdir("/tmp/cats-v-dogs")
    os.mkdir("/tmp/cats-v-dogs/training")
    os.mkdir("/tmp/cats-v-dogs/training/cats")
    os.mkdir("/tmp/cats-v-dogs/training/dogs/")
    os.mkdir("/tmp/cats-v-dogs/testing")
    os.mkdir("/tmp/cats-v-dogs/testing/cats")
    os.mkdir("/tmp/cats-v-dogs/testing/dogs")
except OSError:
    print("Some Error happens!!")
    pass
In [8]:
from random import shuffle
# Write a python function called split_data which takes
# a SOURCE directory containing the files
# a TRAINING directory that a portion of the files will be copied to
# a TESTING directory that a portion of the files will be copie to
# a SPLIT SIZE to determine the portion
# The files should also be randomized, so that the training set is a random
# X% of the files, and the test set is the remaining files
# SO, for example, if SOURCE is PetImages/Cat, and SPLIT SIZE is .9
# Then 90% of the images in PetImages/Cat will be copied to the TRAINING dir
# and 10% of the images will be copied to the TESTING dir
# Also -- All images should be checked, and if they have a zero file length,
# they will not be copied over
#
# os.listdir(DIRECTORY) gives you a listing of the contents of that directory
# os.path.getsize(PATH) gives you the size of the file
# copyfile(source, destination) copies a file from source to destination
# random.sample(list, len(list)) shuffles a list
def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):
    # YOUR CODE STARTS HERE
    all_images = os.listdir(SOURCE)
    shuffle(all_images)
    splitting_index = round(SPLIT_SIZE*len(all_images))
    train_images = all_images[:splitting_index]
    test_images = all_images[splitting_index:]
    #copy training images
    for img in train_images:
        src = os.path.join(SOURCE, img)
        dst = os.path.join(TRAINING, img)
        if os.path.getsize(src) <= 0:
            print(img+" is zero length, so ignoring!!")
        else:
            shutil.copyfile(src, dst)
    #copy testing images
    for img in test_images:
        src = os.path.join(SOURCE, img)
        dst = os.path.join(TESTING, img)
        if os.path.getsize(src) <= 0:
            print(img+" is zero length, so ignoring!!")
        else:
            shutil.copyfile(src, dst)
    # YOUR CODE ENDS HERE
    
    


CAT_SOURCE_DIR = "/tmp/PetImages/Cat/"
TRAINING_CATS_DIR = "/tmp/cats-v-dogs/training/cats/"
TESTING_CATS_DIR = "/tmp/cats-v-dogs/testing/cats/"
DOG_SOURCE_DIR = "/tmp/PetImages/Dog/"
TRAINING_DOGS_DIR = "/tmp/cats-v-dogs/training/dogs/"
TESTING_DOGS_DIR = "/tmp/cats-v-dogs/testing/dogs/"

split_size = .9
split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)
split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)

# Expected output
# 666.jpg is zero length, so ignoring
# 11702.jpg is zero length, so ignoring
666.jpg is zero length, so ignoring!!
11702.jpg is zero length, so ignoring!!
In [9]:
print(len(os.listdir('/tmp/cats-v-dogs/training/cats/')))
print(len(os.listdir('/tmp/cats-v-dogs/training/dogs/')))
print(len(os.listdir('/tmp/cats-v-dogs/testing/cats/')))
print(len(os.listdir('/tmp/cats-v-dogs/testing/dogs/')))

# Expected output:
# 11250
# 11250
# 1250
# 1250
11250
11250
1250
1250
In [0]:
# DEFINE A KERAS MODEL TO CLASSIFY CATS V DOGS
# USE AT LEAST 3 CONVOLUTION LAYERS
model = tf.keras.models.Sequential([
                # YOUR CODE HERE
                tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),
                tf.keras.layers.MaxPooling2D(2,2),
                tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
                tf.keras.layers.MaxPooling2D(2,2),
                tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
                tf.keras.layers.MaxPooling2D(2,2),
                tf.keras.layers.Flatten(),
                tf.keras.layers.Dense(512, activation='relu'),
                tf.keras.layers.Dense(1, activation='sigmoid')
                ])

model.compile(optimizer=RMSprop(lr=0.001),
              loss='binary_crossentropy',
              metrics=['acc'])
In [14]:
TRAINING_DIR = '/tmp/cats-v-dogs/training' #YOUR CODE HERE
train_datagen = ImageDataGenerator(rescale=1./255.)#YOUR CODE HERE
train_generator = train_datagen.flow_from_directory(TRAINING_DIR,
                                                    batch_size=100,
                                                    class_mode='binary',
                                                    target_size=(150, 150))


VALIDATION_DIR = '/tmp/cats-v-dogs/testing' #YOUR CODE HERE
validation_datagen = ImageDataGenerator(rescale=1./255.)#YOUR CODE HERE
validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,
                                                              batch_size=100,
                                                              class_mode='binary',
                                                              target_size=(150, 150))


# Expected Output:
# Found 22498 images belonging to 2 classes.
# Found 2500 images belonging to 2 classes.
Found 22499 images belonging to 2 classes.
Found 2499 images belonging to 2 classes.
In [15]:
#NOTE:
#   The validation data will raise a warning due to corrupt EXIF data of the images, so I will suppress them.
#   If you don't want to do that, you can comment the following two lines
import warnings
warnings.filterwarnings("ignore")

history = model.fit_generator(train_generator,
                              epochs=15,
                              verbose=1,
                              validation_data=validation_generator)

# The expectation here is that the model will train, and that accuracy will be > 95% on both training and validation
# i.e. acc:A1 and val_acc:A2 will be visible, and both A1 and A2 will be > .9
Epoch 1/15
25/25 [==============================] - 9s 374ms/step - loss: 0.5253 - acc: 0.7399
225/225 [==============================] - 82s 365ms/step - loss: 0.6814 - acc: 0.6388 - val_loss: 0.5253 - val_acc: 0.7399
Epoch 2/15
25/25 [==============================] - 9s 370ms/step - loss: 0.4592 - acc: 0.7907
225/225 [==============================] - 80s 355ms/step - loss: 0.5098 - acc: 0.7512 - val_loss: 0.4592 - val_acc: 0.7907
Epoch 3/15
25/25 [==============================] - 10s 394ms/step - loss: 0.4203 - acc: 0.8119
225/225 [==============================] - 80s 356ms/step - loss: 0.4326 - acc: 0.7993 - val_loss: 0.4203 - val_acc: 0.8119
Epoch 4/15
25/25 [==============================] - 9s 370ms/step - loss: 0.4020 - acc: 0.8271
225/225 [==============================] - 82s 364ms/step - loss: 0.3665 - acc: 0.8352 - val_loss: 0.4020 - val_acc: 0.8271
Epoch 5/15
25/25 [==============================] - 10s 383ms/step - loss: 0.4261 - acc: 0.8259
225/225 [==============================] - 80s 357ms/step - loss: 0.2971 - acc: 0.8710 - val_loss: 0.4261 - val_acc: 0.8259
Epoch 6/15
25/25 [==============================] - 9s 369ms/step - loss: 0.3965 - acc: 0.8303
225/225 [==============================] - 81s 360ms/step - loss: 0.2259 - acc: 0.9076 - val_loss: 0.3965 - val_acc: 0.8303
Epoch 7/15
25/25 [==============================] - 9s 372ms/step - loss: 0.5706 - acc: 0.8155
225/225 [==============================] - 81s 362ms/step - loss: 0.1510 - acc: 0.9424 - val_loss: 0.5706 - val_acc: 0.8155
Epoch 8/15
25/25 [==============================] - 9s 371ms/step - loss: 0.7653 - acc: 0.7979
225/225 [==============================] - 80s 357ms/step - loss: 0.0942 - acc: 0.9653 - val_loss: 0.7653 - val_acc: 0.7979
Epoch 9/15
25/25 [==============================] - 9s 366ms/step - loss: 0.6507 - acc: 0.8239
225/225 [==============================] - 81s 359ms/step - loss: 0.0668 - acc: 0.9779 - val_loss: 0.6507 - val_acc: 0.8239
Epoch 10/15
25/25 [==============================] - 9s 378ms/step - loss: 0.9077 - acc: 0.8019
225/225 [==============================] - 81s 361ms/step - loss: 0.0524 - acc: 0.9839 - val_loss: 0.9077 - val_acc: 0.8019
Epoch 11/15
25/25 [==============================] - 9s 368ms/step - loss: 0.7512 - acc: 0.8159
225/225 [==============================] - 82s 365ms/step - loss: 0.0507 - acc: 0.9849 - val_loss: 0.7512 - val_acc: 0.8159
Epoch 12/15
25/25 [==============================] - 9s 369ms/step - loss: 0.8932 - acc: 0.8279
225/225 [==============================] - 81s 359ms/step - loss: 0.0433 - acc: 0.9875 - val_loss: 0.8932 - val_acc: 0.8279
Epoch 13/15
25/25 [==============================] - 9s 365ms/step - loss: 1.0939 - acc: 0.8171
225/225 [==============================] - 80s 355ms/step - loss: 0.0382 - acc: 0.9896 - val_loss: 1.0939 - val_acc: 0.8171
Epoch 14/15
25/25 [==============================] - 9s 364ms/step - loss: 0.9340 - acc: 0.8191
225/225 [==============================] - 80s 355ms/step - loss: 0.0458 - acc: 0.9883 - val_loss: 0.9340 - val_acc: 0.8191
Epoch 15/15
25/25 [==============================] - 9s 368ms/step - loss: 0.9766 - acc: 0.8243
225/225 [==============================] - 82s 363ms/step - loss: 0.0674 - acc: 0.9889 - val_loss: 0.9766 - val_acc: 0.8243
In [16]:
# PLOT LOSS AND ACCURACY
%matplotlib inline

import matplotlib.image  as mpimg
import matplotlib.pyplot as plt

#-----------------------------------------------------------
# Retrieve a list of list results on training and test data
# sets for each training epoch
#-----------------------------------------------------------
acc=history.history['acc']
val_acc=history.history['val_acc']
loss=history.history['loss']
val_loss=history.history['val_loss']

epochs=range(len(acc)) # Get number of epochs

#------------------------------------------------
# Plot training and validation accuracy per epoch
#------------------------------------------------
plt.plot(epochs, acc, 'r', "Training Accuracy")
plt.plot(epochs, val_acc, 'b', "Validation Accuracy")
plt.title('Training and validation accuracy')
plt.figure()

#------------------------------------------------
# Plot training and validation loss per epoch
#------------------------------------------------
plt.plot(epochs, loss, 'r', "Training Loss")
plt.plot(epochs, val_loss, 'b', "Validation Loss")


plt.title('Training and validation loss')

# Desired output. Charts with training and validation metrics. No crash :)
Out[16]:
Text(0.5, 1.0, 'Training and validation loss')


In [21]:
# Here's a codeblock just for fun. You should be able to upload an image here 
# and have it classified without crashing

import numpy as np
from google.colab import files
from keras.preprocessing import image

uploaded = files.upload()

for fn in uploaded.keys():

    # predicting images
    path = '/content/' + fn
    img = image.load_img(path, target_size=(150, 150))
    x = image.img_to_array(img)
    x = np.expand_dims(x, axis=0)

    images = np.vstack([x])
    classes = model.predict(images, batch_size=10)
    print(classes[0])
    if classes[0]>0.5:
        print(fn + " is a dog")
    else:
        print(fn + " is a cat")
Saving Photo0333.jpg to Photo0333.jpg
[1.]
Photo0333.jpg is a dog